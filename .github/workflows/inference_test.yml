name: 'AI inference Test'

on: workflow_dispatch

jobs:
  lint-and-inference:
    runs-on: ubuntu-latest
    permissions:
      models: read
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Run Basic AI Inference
        id: basic_test
        uses: actions/ai-inference@v1
        with:
          prompt: "This is a basic test prompt. What is the weather like today?"
          max-tokens: 100

      - name: Print Output for Basic Prompt
        run: echo "${{ steps.basic_test.outputs.response }}"

      - name: Read MUD system prompt file
        id: read_mud_prompt
        run: |
          content="$(cat .github/prompts/documentation/mud-system.md)"
          # Escape special characters for GitHub Actions output
          content="${content//'%'/'%25'}"
          content="${content//$'\n'/'%0A'}"
          content="${content//$'\r'/'%0D'}"
          echo "prompt_content=$content" >> $GITHUB_OUTPUT

      - name: Run AI Inference with Prompt Content
        id: inference_file
        uses: actions/ai-inference@v1
        with:
          prompt: ${{ steps.read_mud_prompt.outputs.prompt_content }}
          max-tokens: 1000

      - name: Print AI Output from prompt file
        run: |
          echo "Prompt-file response:"
          cat <<EOF
${{ steps.inference_file.outputs.response }}
EOF
